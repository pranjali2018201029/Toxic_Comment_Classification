{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_NN_CV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVM8UoozmpPs",
        "colab_type": "code",
        "outputId": "7af5b368-7eb8-431f-c577-414250626868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ7Xh22smkDd",
        "colab_type": "code",
        "outputId": "f68df7a0-7902-406a-9950-98c62ea3579e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6-h4zT-nTOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Create_NN_Model(No_Features=300, No_Hidden_Layers=1, No_Hidden_Neurons=4, \n",
        "                    Hidden_Activation =\"relu\", No_OP_Neurons=6, \n",
        "                    Output_Activation=\"softmax\", Kernel_Initializer=\"random_uniform\",\n",
        "                    Learning_Rate=0.001, Loss='categorical_crossentropy', \n",
        "                    Metrics =['accuracy']):\n",
        "  \n",
        "  Optimizer = optimizers.RMSprop(lr=Learning_Rate)\n",
        "  classifier = Sequential()\n",
        "\n",
        "  ## Input Layer\n",
        "  classifier.add(Dense(No_Hidden_Neurons, activation=Hidden_Activation, \n",
        "                       kernel_initializer=Kernel_Initializer, input_dim=No_Features))\n",
        "  classifier.add(Dropout(0.3))\n",
        "  \n",
        "  ## Hidden layers\n",
        "  for i in range(No_Hidden_Layers-1):\n",
        "    classifier.add(Dense(No_Hidden_Neurons, activation=Hidden_Activation, \n",
        "                         kernel_initializer=Kernel_Initializer))\n",
        "    classifier.add(Dropout(0.3))\n",
        "    \n",
        "  ## Output Layer\n",
        "  classifier.add(Dense(No_OP_Neurons, activation=Output_Activation, \n",
        "                       kernel_initializer=Kernel_Initializer))\n",
        "  \n",
        "  classifier.summary()\n",
        "  classifier.compile(optimizer =Optimizer, loss=Loss, metrics = Metrics)\n",
        "\n",
        "  return classifier\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVmjjHO3np66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Train_NN(NN_classifier, train_data, feature_list=[], Label_List=[], Batch_Size=64, Epochs=100):\n",
        "\n",
        "  # train_data = train_data.apply(pd.to_numeric, errors='coerce')\n",
        "  # train_data = train_data.dropna()\n",
        "\n",
        "  train_data.dropna()\n",
        "  train_data = pd.DataFrame(np.nan_to_num(np.array(train_data)), columns = train_data.columns)\n",
        "  for label in Label_List:\n",
        "    train_data[label] = pd.to_numeric(train_data[label], errors='coerce')\n",
        "  train_data = train_data.dropna(subset=Label_List)\n",
        "  \n",
        "  train_features = train_data[feature_list] \n",
        "  # train_features = (train_features-train_features.mean())/train_features.std()   \n",
        "  train_labels = train_data[Label_List]\n",
        "  train_labels = train_labels.astype('int')\n",
        "\n",
        "  NN_classifier.fit(train_features,train_labels, batch_size=Batch_Size, epochs=Epochs)\n",
        "\n",
        "  eval_model=NN_classifier.evaluate(train_features, train_labels)\n",
        "  print(\"Loss: \", eval_model[0])\n",
        "  print(\"Accuracy of the model: \", eval_model[1])\n",
        "\n",
        "  return NN_classifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlpTKvRun02c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Store_Trained_NN(NN_obj, Filepath):\n",
        "  \n",
        "  with open(Filepath, \"wb\") as file:\n",
        "    pickle.dump(NN_obj, file)\n",
        "\n",
        "def Load_Trained_NN(Filepath):\n",
        "  \n",
        "  with open(Filepath, \"rb\") as file:\n",
        "    NN_obj = pickle.load(file)\n",
        "\n",
        "  return NN_obj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn4P0QxSn52F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Evaluate_NN(test_data, NN_Model_FilePath, feature_list=[], Label_List=[], threshold=0.5):\n",
        "  \n",
        "  test_data = test_data.fillna(1e-10)\n",
        "\n",
        "  test_data.dropna()\n",
        "  test_data = pd.DataFrame(np.nan_to_num(np.array(test_data)), columns = test_data.columns)\n",
        "  for label in Label_List:\n",
        "    test_data[label] = pd.to_numeric(test_data[label], errors='coerce')\n",
        "  test_data = test_data.dropna(subset=Label_List)\n",
        "\n",
        "  test_features = test_data[feature_list]\n",
        "  test_labels = test_data[Label_List]\n",
        "  test_labels = test_labels.astype('int')\n",
        "\n",
        "  NN_obj = Load_Trained_NN(NN_Model_FilePath) \n",
        "  predictions = NN_obj.predict(test_features)\n",
        "\n",
        "  print(\"test_labels shape: \", test_labels.shape)\n",
        "  print(\"predictions: \", predictions.shape)\n",
        " \n",
        "  loss = log_loss(test_labels,predictions)\n",
        "  print(\"Log_loss : {}\".format(loss))\n",
        "  predictions = np.round(predictions)\n",
        "  loss = hamming_loss(test_labels,predictions)\n",
        "  print(\"Hamming_loss : {}\".format(loss*100))\n",
        "  accuracy = accuracy_score(test_labels,predictions)\n",
        "  print(\"Accuracy : {}\".format(accuracy*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppzHa8sLoDQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GLOVE EMBEDDINGS\n",
        "\n",
        "Column_List = [ \"id\", \"comment_text\"]\n",
        "Label_List = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "Vector_Size = 300\n",
        "Embedding_Cols = [str(i) for i in range(Vector_Size)]\n",
        "Column_List.extend(Embedding_Cols)\n",
        "Column_List.extend(Label_List)\n",
        "\n",
        "Train_Embedding_FilePath = \"/content/drive/My Drive/Train_Glove_Embeddings.csv\"\n",
        "Test_Embedding_FilePath = \"/content/drive/My Drive/Test_Glove_Embeddings.csv\"\n",
        "NN_Model_FilePath = \"/content/NN_Glove_Train_Model.pkl\"\n",
        "\n",
        "test_data = pd.read_csv(Test_Embedding_FilePath, usecols=Column_List)\n",
        "train_data = pd.read_csv(Train_Embedding_FilePath, usecols=Column_List)\n",
        "train_data = train_data.fillna(1e-10)\n",
        "\n",
        "X_train = train_data[Embedding_Cols]\n",
        "Y_train = train_data[Label_List]\n",
        "Y_train = Y_train.astype('int')\n",
        "\n",
        "X_test = test_data[Embedding_Cols]\n",
        "Y_test = test_data[Label_List]\n",
        "Y_test = Y_test.astype('int')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRuBzEXDoJMD",
        "colab_type": "code",
        "outputId": "f81a910e-6abe-4f0e-c671-a5a7227aa0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "## CROSS VALIDATION\n",
        "%%capture\n",
        "#define parameters for using in param grid\n",
        "hidden_nodes = [16, 32, 64] # number of nodes in the hidden layer\n",
        "learning_rates = [0.001, 0.002, 0.003] # learning rate, default = 0.001\n",
        "epochs = [50, 100]\n",
        "batches = [64, 128]\n",
        "\n",
        "model = KerasClassifier(build_fn=Create_NN_Model)\n",
        "\n",
        "#start fitting process\n",
        "param_grid = dict(epochs=epochs, batch_size=batches, No_Hidden_Neurons=hidden_nodes, Learning_Rate=learning_rates)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,refit=True,verbose=2)\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m8_FahwruDZ",
        "colab_type": "code",
        "outputId": "73aff2d5-29f7-43cc-f533-e17eb0964121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(grid_result)\n",
        "print('Best score : {}'.format(grid.best_score_))\n",
        "print('Best params : {}'.format(grid.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
            "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f28d7938748>,\n",
            "             iid='warn', n_jobs=1,\n",
            "             param_grid={'Learning_Rate': [0.001, 0.002, 0.003],\n",
            "                         'No_Hidden_Neurons': [16, 32, 64],\n",
            "                         'batch_size': [64, 128], 'epochs': [50, 100]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=2)\n",
            "Best score : 0.9941656065325153\n",
            "Best params : {'Learning_Rate': 0.003, 'No_Hidden_Neurons': 16, 'batch_size': 64, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8WvR5jQ7Hb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Store cross validation result in a file\n",
        "import pickle\n",
        "with open(\"/content/drive/My Drive/NN_CV_Result.pkl\", \"wb\") as file:\n",
        "  pickle.dump(grid, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNlRY4BErupF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = grid.predict(X_test)\n",
        "predict = grid.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41vp9TuI8NU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_onehot = np.empty(predict.shape)\n",
        "for i in range(predict.shape[0]):\n",
        "  for j in range(predict.shape[1]):\n",
        "    if predict[i][j] < 0.5:\n",
        "      predict_onehot[i][j] = 0\n",
        "    else:\n",
        "      predict_onehot[i][j] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT3lZxaT6bQ9",
        "colab_type": "code",
        "outputId": "830bb352-a1dc-4590-eee9-16ffdeb892bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#calculate score\n",
        "loss = log_loss(Y_test,predict_onehot)\n",
        "print(\"Log_loss : {}\".format(loss))\n",
        "predict = np.round(predict)\n",
        "loss = hamming_loss(Y_test,predict_onehot)\n",
        "print(\"Hamming_loss : {}\".format(loss*100))\n",
        "accuracy = accuracy_score(Y_test,predict_onehot)\n",
        "print(\"Accuracy : {}\".format(accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log_loss : 1.1222380420845148\n",
            "Hamming_loss : 5.619880648984258\n",
            "Accuracy : 79.49847402699557\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}